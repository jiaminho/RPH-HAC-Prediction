{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "proceds = pd.read_csv('PROCEDURES_ICD.csv')\n",
    "d_proceds = pd.read_csv('D_ICD_PROCEDURES.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling\n",
    "\n",
    "Topic modelling uses unsupervised ML to identify clusters or groups of similar words within a body of text\n",
    "\n",
    "LSA: Latent semantic analysis is a statistical technique for extracting and representing the main ideas in a body of text. LSA is based on the principle that words that are close in meaning tend to be used together in context.\n",
    "\n",
    "Latent Dirichlet analysis is one of the most popular topic modeling methods. It uncovers the hidden structure in a set of observations by looking at the relationships between words in a document and grouping them into topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "admissions = pd.read_csv('ADMISSIONS.csv')\n",
    "# get all the individual hadm_id\n",
    "hadm_ids = admissions['HADM_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two tables\n",
    "df_proceds = pd.merge(proceds, d_proceds, on='ICD9_CODE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proceds = df_proceds[['HADM_ID','ICD9_CODE', 'LONG_TITLE']] # extract the columns we need\n",
    "df_proceds['ICD9_CODE'] = df_proceds['ICD9_CODE'].astype(str) # convert the ICD9_CODE to string\n",
    "agg_proceds = df_proceds.groupby('HADM_ID')['ICD9_CODE'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3809, 58976)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_procedures = d_proceds['ICD9_CODE'].unique()\n",
    "num_unique_prods, num_ids = len(unique_procedures), len(hadm_ids)\n",
    "num_unique_prods, num_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string\n",
    "unique_procedures = [str(x) for x in unique_procedures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>859</th>\n",
       "      <th>861</th>\n",
       "      <th>862</th>\n",
       "      <th>863</th>\n",
       "      <th>864</th>\n",
       "      <th>869</th>\n",
       "      <th>870</th>\n",
       "      <th>...</th>\n",
       "      <th>9233</th>\n",
       "      <th>9239</th>\n",
       "      <th>9241</th>\n",
       "      <th>9957</th>\n",
       "      <th>9958</th>\n",
       "      <th>9959</th>\n",
       "      <th>9960</th>\n",
       "      <th>9961</th>\n",
       "      <th>9962</th>\n",
       "      <th>9963</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58971</th>\n",
       "      <td>191113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58972</th>\n",
       "      <td>101071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58973</th>\n",
       "      <td>122631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58974</th>\n",
       "      <td>170407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58975</th>\n",
       "      <td>190264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58976 rows × 3810 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID  851  852  859  861  862  863  864  869  870  ...  9233  9239  \\\n",
       "0       165315    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "1       152223    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "2       124321    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "3       161859    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "4       129635    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "58971   191113    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58972   101071    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58973   122631    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58974   170407    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58975   190264    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "\n",
       "       9241  9957  9958  9959  9960  9961  9962  9963  \n",
       "0         0     0     0     0     0     0     0     0  \n",
       "1         0     0     0     0     0     0     0     0  \n",
       "2         0     0     0     0     0     0     0     0  \n",
       "3         0     0     0     0     0     0     0     0  \n",
       "4         0     0     0     0     0     0     0     0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "58971     0     0     0     0     0     0     0     0  \n",
       "58972     0     0     0     0     0     0     0     0  \n",
       "58973     0     0     0     0     0     0     0     0  \n",
       "58974     0     0     0     0     0     0     0     0  \n",
       "58975     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[58976 rows x 3810 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_length = num_unique_prods  # Assuming IDs start from 0 and are contiguous\n",
    "binary_tensor = np.zeros((num_ids, vector_length), dtype=int)\n",
    "d = pd.DataFrame(binary_tensor, columns=unique_procedures)\n",
    "d.index = hadm_ids\n",
    "# change name of index column\n",
    "d.index.name = 'HADM_ID'\n",
    "d.reset_index(inplace=True)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_proceds = agg_proceds.explode().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populating the OHV, this takes a while\n",
    "for i in range(len(agg_proceds)):\n",
    "    hadm = agg_proceds.loc[i]['HADM_ID']\n",
    "    icd9 = agg_proceds.loc[i]['ICD9_CODE']\n",
    "    d.loc[d['HADM_ID'] == hadm, icd9] = 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find HADM_IDs that have diagnosis with 5990\n",
    "diagnoses = pd.read_csv('DIAGNOSES_ICD.csv')\n",
    "d_diagnoses = pd.read_csv('D_ICD_DIAGNOSES.csv')\n",
    "\n",
    "# combine the two tables, based on ICD9_CODE, without short title\n",
    "df_diag = pd.merge(diagnoses, d_diagnoses, on='ICD9_CODE', how='left')\n",
    "df_diag = df_diag.dropna(subset=['ICD9_CODE'])\n",
    "df_diag['ICD9_CODE'] = df_diag['ICD9_CODE'].astype(str)\n",
    "df_diag = df_diag[['HADM_ID','ICD9_CODE', 'LONG_TITLE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([114585, 134369, 191817, ..., 122472, 109999, 161999])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if the diagnosis is 5990\n",
    "df_diag['UTI'] = df_diag['ICD9_CODE'].apply(lambda x: 1 if x == '5990' else 0)\n",
    "# get the hadm_id that has diagnosis 5990\n",
    "hadm_ids_5990 = df_diag[df_diag['UTI'] == 1]['HADM_ID'].unique()\n",
    "hadm_ids_5990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>851</th>\n",
       "      <th>852</th>\n",
       "      <th>859</th>\n",
       "      <th>861</th>\n",
       "      <th>862</th>\n",
       "      <th>863</th>\n",
       "      <th>864</th>\n",
       "      <th>869</th>\n",
       "      <th>870</th>\n",
       "      <th>...</th>\n",
       "      <th>9239</th>\n",
       "      <th>9241</th>\n",
       "      <th>9957</th>\n",
       "      <th>9958</th>\n",
       "      <th>9959</th>\n",
       "      <th>9960</th>\n",
       "      <th>9961</th>\n",
       "      <th>9962</th>\n",
       "      <th>9963</th>\n",
       "      <th>UTI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>152223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124321</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>161859</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>129635</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58971</th>\n",
       "      <td>191113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58972</th>\n",
       "      <td>101071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58973</th>\n",
       "      <td>122631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58974</th>\n",
       "      <td>170407</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58975</th>\n",
       "      <td>190264</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58976 rows × 3811 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       HADM_ID  851  852  859  861  862  863  864  869  870  ...  9239  9241  \\\n",
       "0       165315    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "1       152223    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "2       124321    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "3       161859    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "4       129635    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "...        ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "58971   191113    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58972   101071    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58973   122631    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58974   170407    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "58975   190264    0    0    0    0    0    0    0    0    0  ...     0     0   \n",
       "\n",
       "       9957  9958  9959  9960  9961  9962  9963  UTI  \n",
       "0         0     0     0     0     0     0     0    0  \n",
       "1         0     0     0     0     0     0     0    0  \n",
       "2         0     0     0     0     0     0     0    0  \n",
       "3         0     0     0     0     0     0     0    0  \n",
       "4         0     0     0     0     0     0     0    0  \n",
       "...     ...   ...   ...   ...   ...   ...   ...  ...  \n",
       "58971     0     0     0     0     0     0     0    0  \n",
       "58972     0     0     0     0     0     0     0    0  \n",
       "58973     0     0     0     0     0     0     0    0  \n",
       "58974     0     0     0     0     0     0     0    1  \n",
       "58975     0     0     0     0     0     0     0    0  \n",
       "\n",
       "[58976 rows x 3811 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into train and test\n",
    "X = d.drop(['HADM_ID', 'UTI'], axis=1)\n",
    "y = d['UTI']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoders\n",
    "\n",
    "We reduce the sparse OHV down to 32 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train.shape[1]\n",
    "encoding_dim = 64\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1475/1475 [==============================] - 1s 439us/step\n"
     ]
    }
   ],
   "source": [
    "encoded = autoencoder.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "738/738 [==============================] - 1s 649us/step - loss: 0.6570 - accuracy: 0.5966\n",
      "Epoch 2/100\n",
      "738/738 [==============================] - 0s 655us/step - loss: 0.6319 - accuracy: 0.5697\n",
      "Epoch 3/100\n",
      "738/738 [==============================] - 0s 670us/step - loss: 0.6261 - accuracy: 0.5765\n",
      "Epoch 4/100\n",
      "738/738 [==============================] - 0s 648us/step - loss: 0.6221 - accuracy: 0.5874\n",
      "Epoch 5/100\n",
      "738/738 [==============================] - 0s 652us/step - loss: 0.6180 - accuracy: 0.5936\n",
      "Epoch 6/100\n",
      "738/738 [==============================] - 0s 644us/step - loss: 0.6158 - accuracy: 0.5882\n",
      "Epoch 7/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.6135 - accuracy: 0.5850\n",
      "Epoch 8/100\n",
      "738/738 [==============================] - 0s 671us/step - loss: 0.6117 - accuracy: 0.5726\n",
      "Epoch 9/100\n",
      "738/738 [==============================] - 0s 640us/step - loss: 0.6108 - accuracy: 0.5820\n",
      "Epoch 10/100\n",
      "738/738 [==============================] - 0s 638us/step - loss: 0.6082 - accuracy: 0.5875\n",
      "Epoch 11/100\n",
      "738/738 [==============================] - 0s 632us/step - loss: 0.6050 - accuracy: 0.5896\n",
      "Epoch 12/100\n",
      "738/738 [==============================] - 0s 634us/step - loss: 0.6027 - accuracy: 0.5995\n",
      "Epoch 13/100\n",
      "738/738 [==============================] - 0s 654us/step - loss: 0.6012 - accuracy: 0.6024\n",
      "Epoch 14/100\n",
      "738/738 [==============================] - 0s 637us/step - loss: 0.6019 - accuracy: 0.5928\n",
      "Epoch 15/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5974 - accuracy: 0.5902\n",
      "Epoch 16/100\n",
      "738/738 [==============================] - 0s 640us/step - loss: 0.5968 - accuracy: 0.5945\n",
      "Epoch 17/100\n",
      "738/738 [==============================] - 0s 644us/step - loss: 0.5932 - accuracy: 0.6027\n",
      "Epoch 18/100\n",
      "738/738 [==============================] - 0s 660us/step - loss: 0.5949 - accuracy: 0.6045\n",
      "Epoch 19/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5910 - accuracy: 0.5979\n",
      "Epoch 20/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5895 - accuracy: 0.6069\n",
      "Epoch 21/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5894 - accuracy: 0.6005\n",
      "Epoch 22/100\n",
      "738/738 [==============================] - 0s 637us/step - loss: 0.5894 - accuracy: 0.6114\n",
      "Epoch 23/100\n",
      "738/738 [==============================] - 0s 653us/step - loss: 0.5865 - accuracy: 0.6024\n",
      "Epoch 24/100\n",
      "738/738 [==============================] - 0s 631us/step - loss: 0.5840 - accuracy: 0.6029\n",
      "Epoch 25/100\n",
      "738/738 [==============================] - 0s 637us/step - loss: 0.5848 - accuracy: 0.6031\n",
      "Epoch 26/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5831 - accuracy: 0.6078\n",
      "Epoch 27/100\n",
      "738/738 [==============================] - 0s 634us/step - loss: 0.5805 - accuracy: 0.6071\n",
      "Epoch 28/100\n",
      "738/738 [==============================] - 0s 647us/step - loss: 0.5796 - accuracy: 0.6056\n",
      "Epoch 29/100\n",
      "738/738 [==============================] - 0s 654us/step - loss: 0.5798 - accuracy: 0.6120\n",
      "Epoch 30/100\n",
      "738/738 [==============================] - 0s 646us/step - loss: 0.5763 - accuracy: 0.6104\n",
      "Epoch 31/100\n",
      "738/738 [==============================] - 0s 637us/step - loss: 0.5764 - accuracy: 0.6005\n",
      "Epoch 32/100\n",
      "738/738 [==============================] - 0s 642us/step - loss: 0.5745 - accuracy: 0.6139\n",
      "Epoch 33/100\n",
      "738/738 [==============================] - 0s 654us/step - loss: 0.5756 - accuracy: 0.6056\n",
      "Epoch 34/100\n",
      "738/738 [==============================] - 1s 685us/step - loss: 0.5721 - accuracy: 0.6127\n",
      "Epoch 35/100\n",
      "738/738 [==============================] - 0s 651us/step - loss: 0.5713 - accuracy: 0.6122\n",
      "Epoch 36/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5669 - accuracy: 0.6101\n",
      "Epoch 37/100\n",
      "738/738 [==============================] - 0s 647us/step - loss: 0.5674 - accuracy: 0.6149\n",
      "Epoch 38/100\n",
      "738/738 [==============================] - 0s 674us/step - loss: 0.5679 - accuracy: 0.6221\n",
      "Epoch 39/100\n",
      "738/738 [==============================] - 0s 647us/step - loss: 0.5665 - accuracy: 0.6150\n",
      "Epoch 40/100\n",
      "738/738 [==============================] - 0s 635us/step - loss: 0.5657 - accuracy: 0.6196\n",
      "Epoch 41/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5651 - accuracy: 0.6197\n",
      "Epoch 42/100\n",
      "738/738 [==============================] - 0s 655us/step - loss: 0.5633 - accuracy: 0.6055\n",
      "Epoch 43/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5648 - accuracy: 0.6248\n",
      "Epoch 44/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5639 - accuracy: 0.6091\n",
      "Epoch 45/100\n",
      "738/738 [==============================] - 0s 655us/step - loss: 0.5619 - accuracy: 0.6279\n",
      "Epoch 46/100\n",
      "738/738 [==============================] - 0s 648us/step - loss: 0.5620 - accuracy: 0.6175\n",
      "Epoch 47/100\n",
      "738/738 [==============================] - 1s 686us/step - loss: 0.5584 - accuracy: 0.6222\n",
      "Epoch 48/100\n",
      "738/738 [==============================] - 0s 642us/step - loss: 0.5593 - accuracy: 0.6214\n",
      "Epoch 49/100\n",
      "738/738 [==============================] - 0s 640us/step - loss: 0.5569 - accuracy: 0.6286\n",
      "Epoch 50/100\n",
      "738/738 [==============================] - 0s 650us/step - loss: 0.5564 - accuracy: 0.6299\n",
      "Epoch 51/100\n",
      "738/738 [==============================] - 0s 667us/step - loss: 0.5579 - accuracy: 0.6216\n",
      "Epoch 52/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5571 - accuracy: 0.6110\n",
      "Epoch 53/100\n",
      "738/738 [==============================] - 0s 638us/step - loss: 0.5555 - accuracy: 0.6288\n",
      "Epoch 54/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5520 - accuracy: 0.6245\n",
      "Epoch 55/100\n",
      "738/738 [==============================] - 0s 633us/step - loss: 0.5540 - accuracy: 0.6308\n",
      "Epoch 56/100\n",
      "738/738 [==============================] - 0s 651us/step - loss: 0.5530 - accuracy: 0.6323\n",
      "Epoch 57/100\n",
      "738/738 [==============================] - 0s 634us/step - loss: 0.5511 - accuracy: 0.6322\n",
      "Epoch 58/100\n",
      "738/738 [==============================] - 0s 632us/step - loss: 0.5517 - accuracy: 0.6276\n",
      "Epoch 59/100\n",
      "738/738 [==============================] - 0s 634us/step - loss: 0.5478 - accuracy: 0.6280\n",
      "Epoch 60/100\n",
      "738/738 [==============================] - 0s 669us/step - loss: 0.5484 - accuracy: 0.6274\n",
      "Epoch 61/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5488 - accuracy: 0.6344\n",
      "Epoch 62/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5509 - accuracy: 0.6297\n",
      "Epoch 63/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5501 - accuracy: 0.6277\n",
      "Epoch 64/100\n",
      "738/738 [==============================] - 0s 638us/step - loss: 0.5470 - accuracy: 0.6318\n",
      "Epoch 65/100\n",
      "738/738 [==============================] - 0s 660us/step - loss: 0.5449 - accuracy: 0.6333\n",
      "Epoch 66/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5490 - accuracy: 0.6231\n",
      "Epoch 67/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5471 - accuracy: 0.6247\n",
      "Epoch 68/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5463 - accuracy: 0.6323\n",
      "Epoch 69/100\n",
      "738/738 [==============================] - 0s 633us/step - loss: 0.5437 - accuracy: 0.6292\n",
      "Epoch 70/100\n",
      "738/738 [==============================] - 0s 654us/step - loss: 0.5431 - accuracy: 0.6339\n",
      "Epoch 71/100\n",
      "738/738 [==============================] - 0s 632us/step - loss: 0.5447 - accuracy: 0.6356\n",
      "Epoch 72/100\n",
      "738/738 [==============================] - 0s 635us/step - loss: 0.5451 - accuracy: 0.6272\n",
      "Epoch 73/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5443 - accuracy: 0.6305\n",
      "Epoch 74/100\n",
      "738/738 [==============================] - 0s 636us/step - loss: 0.5452 - accuracy: 0.6311\n",
      "Epoch 75/100\n",
      "738/738 [==============================] - 0s 652us/step - loss: 0.5423 - accuracy: 0.6285\n",
      "Epoch 76/100\n",
      "738/738 [==============================] - 0s 636us/step - loss: 0.5407 - accuracy: 0.6357\n",
      "Epoch 77/100\n",
      "738/738 [==============================] - 0s 638us/step - loss: 0.5401 - accuracy: 0.6518\n",
      "Epoch 78/100\n",
      "738/738 [==============================] - 0s 643us/step - loss: 0.5387 - accuracy: 0.6380\n",
      "Epoch 79/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5407 - accuracy: 0.6286\n",
      "Epoch 80/100\n",
      "738/738 [==============================] - 0s 667us/step - loss: 0.5423 - accuracy: 0.6471\n",
      "Epoch 81/100\n",
      "738/738 [==============================] - 0s 645us/step - loss: 0.5383 - accuracy: 0.6371\n",
      "Epoch 82/100\n",
      "738/738 [==============================] - 0s 650us/step - loss: 0.5395 - accuracy: 0.6444\n",
      "Epoch 83/100\n",
      "738/738 [==============================] - 0s 642us/step - loss: 0.5376 - accuracy: 0.6311\n",
      "Epoch 84/100\n",
      "738/738 [==============================] - 0s 660us/step - loss: 0.5369 - accuracy: 0.6406\n",
      "Epoch 85/100\n",
      "738/738 [==============================] - 0s 635us/step - loss: 0.5331 - accuracy: 0.6325\n",
      "Epoch 86/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5373 - accuracy: 0.6442\n",
      "Epoch 87/100\n",
      "738/738 [==============================] - 0s 637us/step - loss: 0.5380 - accuracy: 0.6303\n",
      "Epoch 88/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5374 - accuracy: 0.6379\n",
      "Epoch 89/100\n",
      "738/738 [==============================] - 0s 659us/step - loss: 0.5339 - accuracy: 0.6324\n",
      "Epoch 90/100\n",
      "738/738 [==============================] - 0s 638us/step - loss: 0.5353 - accuracy: 0.6487\n",
      "Epoch 91/100\n",
      "738/738 [==============================] - 0s 633us/step - loss: 0.5348 - accuracy: 0.6452\n",
      "Epoch 92/100\n",
      "738/738 [==============================] - 0s 641us/step - loss: 0.5378 - accuracy: 0.6329\n",
      "Epoch 93/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5298 - accuracy: 0.6408\n",
      "Epoch 94/100\n",
      "738/738 [==============================] - 0s 655us/step - loss: 0.5338 - accuracy: 0.6481\n",
      "Epoch 95/100\n",
      "738/738 [==============================] - 0s 642us/step - loss: 0.5294 - accuracy: 0.6393\n",
      "Epoch 96/100\n",
      "738/738 [==============================] - 0s 640us/step - loss: 0.5288 - accuracy: 0.6401\n",
      "Epoch 97/100\n",
      "738/738 [==============================] - 0s 639us/step - loss: 0.5312 - accuracy: 0.6481\n",
      "Epoch 98/100\n",
      "738/738 [==============================] - 0s 651us/step - loss: 0.5317 - accuracy: 0.6507\n",
      "Epoch 99/100\n",
      "738/738 [==============================] - 0s 661us/step - loss: 0.5315 - accuracy: 0.6596\n",
      "Epoch 100/100\n",
      "738/738 [==============================] - 0s 645us/step - loss: 0.5329 - accuracy: 0.6353\n"
     ]
    }
   ],
   "source": [
    "# creating a classifier\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "class_weight_0 = len(y_train) / (2 * np.sum(y_train == 0))\n",
    "class_weight_1 = len(y_train) / (2 * np.sum(y_train == 1))\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=encoding_dim, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history = model.fit(encoded, y_train, epochs=100, batch_size=64, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 0s 473us/step\n",
      "369/369 [==============================] - 0s 322us/step - loss: 0.5883 - accuracy: 0.6162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5882849097251892, 0.6162258386611938]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test case\n",
    "encoded_test = autoencoder.predict(x_test)\n",
    "model.evaluate(encoded_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 0s 268us/step\n",
      "1475/1475 [==============================] - 0s 259us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(encoded_test)\n",
    "y_train_pred = model.predict(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6495, 4070],\n",
       "       [ 457,  774]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the accuracy of the model using a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_cm = confusion_matrix(y_test, y_pred.round())\n",
    "train_cm = confusion_matrix(y_train, y_train_pred.round())\n",
    "test_cm    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.18% - Balanced accuracy Test\n",
      "74.57% - Balanced accuracy Train\n"
     ]
    }
   ],
   "source": [
    "# calculate balanced accuracy\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "print(f\"{balanced_accuracy_score(y_test, y_pred.round()) * 100:.2f}% - Balanced accuracy Test\")\n",
    "print(f\"{balanced_accuracy_score(y_train, y_train_pred.round()) * 100:.2f}% - Balanced accuracy Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.656999</td>\n",
       "      <td>0.596630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.631889</td>\n",
       "      <td>0.569691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.626065</td>\n",
       "      <td>0.576452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.622065</td>\n",
       "      <td>0.587368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.618019</td>\n",
       "      <td>0.593620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.528838</td>\n",
       "      <td>0.640102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.531220</td>\n",
       "      <td>0.648050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.531708</td>\n",
       "      <td>0.650678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.531453</td>\n",
       "      <td>0.659559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.532904</td>\n",
       "      <td>0.635290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy\n",
       "0   0.656999  0.596630\n",
       "1   0.631889  0.569691\n",
       "2   0.626065  0.576452\n",
       "3   0.622065  0.587368\n",
       "4   0.618019  0.593620\n",
       "..       ...       ...\n",
       "95  0.528838  0.640102\n",
       "96  0.531220  0.648050\n",
       "97  0.531708  0.650678\n",
       "98  0.531453  0.659559\n",
       "99  0.532904  0.635290\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check model history\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balanced Accuracy comes to be around 0.61% purely based on encoding for the test set.\n",
    "\n",
    "## Trying with the Sparse Vector instead of Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102],\n",
       "       [-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102],\n",
       "       [-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102],\n",
       "       ...,\n",
       "       [-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102],\n",
       "       [-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102],\n",
       "       [-0.0195362 , -0.01381286, -0.00797435, ..., -0.07795773,\n",
       "        -0.1156782 , -0.01527102]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train)\n",
    "x_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.6682 - accuracy: 0.5307\n",
      "Epoch 2/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.6110 - accuracy: 0.5828\n",
      "Epoch 3/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5864 - accuracy: 0.5983\n",
      "Epoch 4/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5697 - accuracy: 0.6173\n",
      "Epoch 5/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5576 - accuracy: 0.6386\n",
      "Epoch 6/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.6467\n",
      "Epoch 7/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5436 - accuracy: 0.6321\n",
      "Epoch 8/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.6406\n",
      "Epoch 9/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5256 - accuracy: 0.6521\n",
      "Epoch 10/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5214 - accuracy: 0.6429\n",
      "Epoch 11/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5164 - accuracy: 0.6604\n",
      "Epoch 12/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5068 - accuracy: 0.6678\n",
      "Epoch 13/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.5024 - accuracy: 0.6626\n",
      "Epoch 14/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4966 - accuracy: 0.6677\n",
      "Epoch 15/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4953 - accuracy: 0.6771\n",
      "Epoch 16/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4878 - accuracy: 0.6748\n",
      "Epoch 17/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.6938\n",
      "Epoch 18/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4809 - accuracy: 0.6875\n",
      "Epoch 19/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4762 - accuracy: 0.6948\n",
      "Epoch 20/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4730 - accuracy: 0.6959\n",
      "Epoch 21/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4726 - accuracy: 0.6967\n",
      "Epoch 22/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4719 - accuracy: 0.6979\n",
      "Epoch 23/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4706 - accuracy: 0.7009\n",
      "Epoch 24/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4678 - accuracy: 0.7018\n",
      "Epoch 25/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4633 - accuracy: 0.7145\n",
      "Epoch 26/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4590 - accuracy: 0.7116\n",
      "Epoch 27/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4565 - accuracy: 0.7145\n",
      "Epoch 28/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4503 - accuracy: 0.7311\n",
      "Epoch 29/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4562 - accuracy: 0.7146\n",
      "Epoch 30/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4495 - accuracy: 0.7141\n",
      "Epoch 31/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4498 - accuracy: 0.7149\n",
      "Epoch 32/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4461 - accuracy: 0.7131\n",
      "Epoch 33/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4462 - accuracy: 0.7216\n",
      "Epoch 34/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4457 - accuracy: 0.7187\n",
      "Epoch 35/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4426 - accuracy: 0.7085\n",
      "Epoch 36/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4390 - accuracy: 0.7161\n",
      "Epoch 37/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4393 - accuracy: 0.7105\n",
      "Epoch 38/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4334 - accuracy: 0.7173\n",
      "Epoch 39/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4360 - accuracy: 0.7192\n",
      "Epoch 40/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4382 - accuracy: 0.7135\n",
      "Epoch 41/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4360 - accuracy: 0.7301\n",
      "Epoch 42/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4342 - accuracy: 0.7187\n",
      "Epoch 43/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4265 - accuracy: 0.7282\n",
      "Epoch 44/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4277 - accuracy: 0.7362\n",
      "Epoch 45/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4288 - accuracy: 0.7336\n",
      "Epoch 46/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4275 - accuracy: 0.7291\n",
      "Epoch 47/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4240 - accuracy: 0.7288\n",
      "Epoch 48/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4252 - accuracy: 0.7253\n",
      "Epoch 49/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4233 - accuracy: 0.7260\n",
      "Epoch 50/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4183 - accuracy: 0.7236\n",
      "Epoch 51/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4169 - accuracy: 0.7305\n",
      "Epoch 52/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4239 - accuracy: 0.7244\n",
      "Epoch 53/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4162 - accuracy: 0.7268\n",
      "Epoch 54/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4167 - accuracy: 0.7316\n",
      "Epoch 55/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4136 - accuracy: 0.7360\n",
      "Epoch 56/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4197 - accuracy: 0.7471\n",
      "Epoch 57/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4173 - accuracy: 0.7382\n",
      "Epoch 58/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4136 - accuracy: 0.7375\n",
      "Epoch 59/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4095 - accuracy: 0.7312\n",
      "Epoch 60/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4124 - accuracy: 0.7457\n",
      "Epoch 61/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4118 - accuracy: 0.7476\n",
      "Epoch 62/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4106 - accuracy: 0.7510\n",
      "Epoch 63/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4088 - accuracy: 0.7378\n",
      "Epoch 64/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4089 - accuracy: 0.7438\n",
      "Epoch 65/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.7463\n",
      "Epoch 66/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4073 - accuracy: 0.7449\n",
      "Epoch 67/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4044 - accuracy: 0.7439\n",
      "Epoch 68/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4072 - accuracy: 0.7393\n",
      "Epoch 69/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4063 - accuracy: 0.7472\n",
      "Epoch 70/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4082 - accuracy: 0.7420\n",
      "Epoch 71/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4065 - accuracy: 0.7420\n",
      "Epoch 72/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4035 - accuracy: 0.7441\n",
      "Epoch 73/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.7562\n",
      "Epoch 74/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4069 - accuracy: 0.7359\n",
      "Epoch 75/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4075 - accuracy: 0.7432\n",
      "Epoch 76/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4058 - accuracy: 0.7420\n",
      "Epoch 77/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4093 - accuracy: 0.7413\n",
      "Epoch 78/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3982 - accuracy: 0.7433\n",
      "Epoch 79/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.7447\n",
      "Epoch 80/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4009 - accuracy: 0.7519\n",
      "Epoch 81/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4001 - accuracy: 0.7475\n",
      "Epoch 82/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4045 - accuracy: 0.7448\n",
      "Epoch 83/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4034 - accuracy: 0.7481\n",
      "Epoch 84/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4036 - accuracy: 0.7410\n",
      "Epoch 85/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.7465\n",
      "Epoch 86/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4008 - accuracy: 0.7448\n",
      "Epoch 87/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3973 - accuracy: 0.7494\n",
      "Epoch 88/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.4006 - accuracy: 0.7453\n",
      "Epoch 89/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3957 - accuracy: 0.7436\n",
      "Epoch 90/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3994 - accuracy: 0.7468\n",
      "Epoch 91/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3945 - accuracy: 0.7585\n",
      "Epoch 92/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3984 - accuracy: 0.7521\n",
      "Epoch 93/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3944 - accuracy: 0.7514\n",
      "Epoch 94/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3976 - accuracy: 0.7585\n",
      "Epoch 95/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3983 - accuracy: 0.7534\n",
      "Epoch 96/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3919 - accuracy: 0.7526\n",
      "Epoch 97/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3989 - accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3986 - accuracy: 0.7571\n",
      "Epoch 99/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3981 - accuracy: 0.7516\n",
      "Epoch 100/100\n",
      "738/738 [==============================] - 1s 1ms/step - loss: 0.3952 - accuracy: 0.7516\n"
     ]
    }
   ],
   "source": [
    "model_sparse = Sequential()\n",
    "model_sparse.add(Dense(64, input_dim=3809, activation='relu'))\n",
    "model_sparse.add(Dropout(0.2))\n",
    "model_sparse.add(Dense(32, activation='relu'))\n",
    "model_sparse.add(Dropout(0.2))\n",
    "model_sparse.add(Dense(16, activation='relu'))\n",
    "model_sparse.add(Dropout(0.2))\n",
    "model_sparse.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_sparse.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "history_sparse = model_sparse.fit(x_train_scaled, y_train, epochs=100, batch_size=64, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369/369 [==============================] - 0s 462us/step - loss: 0.8022 - accuracy: 0.6752\n",
      "369/369 [==============================] - 0s 359us/step\n",
      "1475/1475 [==============================] - 1s 355us/step\n",
      "59.26% - Balanced accuracy Test\n",
      "81.75% - Balanced accuracy Train\n"
     ]
    }
   ],
   "source": [
    "# test case\n",
    "x_test_scaled = scaler.transform(x_test)\n",
    "model_sparse.evaluate(x_test_scaled, y_test)\n",
    "\n",
    "y_pred_sparse = model_sparse.predict(x_test_scaled)\n",
    "y_train_pred_sparse = model_sparse.predict(x_train_scaled)\n",
    "\n",
    "# check the accuracy of the model using a confusion matrix\n",
    "test_cm_sparse = confusion_matrix(y_test, y_pred_sparse.round())\n",
    "train_cm_sparse = confusion_matrix(y_train, y_train_pred_sparse.round())\n",
    "\n",
    "# calculate balanced accuracy\n",
    "print(f\"{balanced_accuracy_score(y_test, y_pred_sparse.round()) * 100:.2f}% - Balanced accuracy Test\")\n",
    "print(f\"{balanced_accuracy_score(y_train, y_train_pred_sparse.round()) * 100:.2f}% - Balanced accuracy Train\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
